library(caret)
library(randomForest)

credit<-read.csv("credit.csv")
str(credit)
names(credit)
attach(credit)
table(checking_balance)
table(months_loan_duration)
table(savings_balance)
summary(amount)

# convert the default parameter to a factor
credit$default<-factor(credit$default)
# if defaulted 1 (yes) 0 (no default)
credit$default = ifelse(credit$default == "1", 0, 1)
head(credit)
table(credit$default)


split.data=function(data,s=777)
{
  set.seed(s)
  data_rand<-data[order(runif(1000)),]
  train<-data_rand[1:900,]
  test<-data_rand[901:1000,]
  return(list(train=train,test=test))
}


#call the function
dataset= split.data(credit)
credit_train = dataset$train
credit_test = dataset$test

runif(2)
r=runif(2)

#check the default probablity
prop.table(table(credit_train$default))



#**********************************
library(C50)

factor(credit_test$default)


credit.fit<-C5.0(credit_train[-17],factor(credit_test$default))
summary(credit.fit)
credit_pred<-predict(credit.fit, credit_test)
head(credit_pred)

library(gmodels)
CrossTable(credit_test$default, credit_pred, prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE, dnn = c('actual default', 'predicted default'))
table<-table(credit_test$default,credit_pred)
library(caret)
confusionMatrix(table)
misClassError<-mean(credit_pred!=credit_test$default)
print(paste('Accuracy',1-misClassError))
#****************RPART***********DECISION TREE
#Let us first use decision tree
#*********************************************
library(rpart)
fit<-rpart(default~.,data=credit_train,method="class")
pred<-predict(fit, credit_test,type="class")
table=table(credit_test$default,pred)
confusionMatrix(table)
misClassError<-mean(pred!=credit_test$default)
print(paste('Accuracy',1-misClassError))

#prune tree to remove overfitting
names(fit)
#examine contents of cptable
fit$cptable
min(fit$cptable[,"xerror"])
#Find the record with the lowest cross-validation errors:
which.min(fit$cptable[,"xerror"])
#Get the "CP" from the list with the lowest cross-validation errors:
credit.cp = fit$cptable[7,"CP"]
credit.cp
#Prune the tree :
prune.tree = prune(fit, cp= credit.cp)
#Visualize the classification tree by using the plot and text function:
plot(prune.tree, margin= 0.1)
text(prune.tree, all=TRUE , use.n=TRUE)

#predict
predictions = predict(prune.tree, credit_test, type="class")
table(credit_test$default, predictions)

#Test classification error :
confusionMatrix(table(predictions, credit_test$default))


#*******************************************************
#Let us Logistic regression

fit<-glm(default~., data=credit_train, family=binomial)
glm.pred<-predict(fit, credit_test,family=binomial)
credit_pred = ifelse(glm.pred <= "0.5", 0, 1)
table=table(credit_test$default,credit_pred)
confusionMatrix(table)
summary(fit)

names(credit_train)
head(credit_train$default)
